import { PrismaClient } from '@prisma/client';
import { GeminiClient } from '../lib/geminiClient';
import { QdrantClient } from '../lib/qdrantClient';
import { SolanaClient } from '../lib/solanaClient';
import { IncidentSubmission } from '../types';

const prisma = new PrismaClient();

export class BatchService {
  constructor(
    private gemini: GeminiClient,
    private qdrant: QdrantClient,
    private solana: SolanaClient
  ) {}

  /**
   * Process batch of incidents with parallel execution
   */
  async processBatch(
    incidents: IncidentSubmission[],
    options: {
      parallel?: boolean;
      maxConcurrency?: number;
    } = {}
  ): Promise<{
    batch_id: string;
    total: number;
    processed: number;
    failed: number;
    processing_time_ms: number;
    sequential_time_estimate: number;
    performance_improvement: string;
    results: any[];
  }> {
    const startTime = Date.now();
    const batchId = `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    console.log(`üîÑ Starting batch ${batchId} with ${incidents.length} incidents`);

    // Validate credits for all incidents
    const wallet = incidents[0].reporter_wallet;
    const credits = await this.solana.getCredits(wallet);

    if (credits < incidents.length) {
      throw new Error(
        `Insufficient credits. Required: ${incidents.length}, Available: ${credits}`
      );
    }

    // Create batch record
    await prisma.$executeRaw`
      INSERT INTO batches (id, wallet_address, total_incidents, status, created_at)
      VALUES (${batchId}, ${wallet}, ${incidents.length}, 'processing', NOW())
    `;

    const results: any[] = [];
    const errors: any[] = [];

    if (options.parallel !== false) {
      // PARALLEL PROCESSING (default)
      const maxConcurrency = options.maxConcurrency || 10;

      console.log(`‚ö° Processing ${incidents.length} incidents in parallel (max concurrency: ${maxConcurrency})`);

      // Process in chunks to avoid overwhelming APIs
      for (let i = 0; i < incidents.length; i += maxConcurrency) {
        const chunk = incidents.slice(i, i + maxConcurrency);

        const chunkResults = await Promise.allSettled(
          chunk.map((incident, idx) =>
            this.processSingleIncident(incident, `${batchId}_${i + idx}`)
          )
        );

        chunkResults.forEach((result, idx) => {
          if (result.status === 'fulfilled') {
            results.push(result.value);
          } else {
            errors.push({
              index: i + idx,
              error: result.reason.message,
            });
          }
        });

        console.log(`‚úÖ Processed chunk ${i / maxConcurrency + 1}/${Math.ceil(incidents.length / maxConcurrency)}`);
      }
    } else {
      // SEQUENTIAL PROCESSING (for comparison)
      console.log(`üêå Processing ${incidents.length} incidents sequentially`);

      for (let i = 0; i < incidents.length; i++) {
        try {
          const result = await this.processSingleIncident(
            incidents[i],
            `${batchId}_${i}`
          );
          results.push(result);
        } catch (error: any) {
          errors.push({ index: i, error: error.message });
        }
      }
    }

    const processingTime = Date.now() - startTime;

    // Estimate sequential time (based on average single incident time of 15 seconds)
    const avgIncidentTime = 15000;
    const sequentialEstimate = incidents.length * avgIncidentTime;
    const improvement = ((sequentialEstimate - processingTime) / sequentialEstimate * 100).toFixed(1);

    // Update batch record
    await prisma.$executeRaw`
      UPDATE batches
      SET status = 'completed',
          processed_count = ${results.length},
          failed_count = ${errors.length},
          processing_time_ms = ${processingTime},
          completed_at = NOW()
      WHERE id = ${batchId}
    `;

    // Decrement credits
    this.solana.decrementMockCredits(wallet, results.length);

    console.log(`‚úÖ Batch ${batchId} complete: ${results.length}/${incidents.length} processed in ${processingTime}ms`);

    return {
      batch_id: batchId,
      total: incidents.length,
      processed: results.length,
      failed: errors.length,
      processing_time_ms: processingTime,
      sequential_time_estimate: sequentialEstimate,
      performance_improvement: `${improvement}% faster than sequential`,
      results,
    };
  }

  /**
   * Process single incident with full pipeline
   */
  private async processSingleIncident(
    submission: IncidentSubmission,
    incidentId: string
  ): Promise<any> {
    const startTime = Date.now();

    // Find or create user
    let user = await prisma.user.findUnique({
      where: { wallet_address: submission.reporter_wallet },
    });

    if (!user) {
      user = await prisma.user.create({
        data: {
          wallet_address: submission.reporter_wallet,
          credits: await this.solana.getCredits(submission.reporter_wallet),
        },
      });
    }

    // Create incident
    const incident = await prisma.incident.create({
      data: {
        id: incidentId,
        reporter_id: user.id,
        text: submission.text,
        incident_type: submission.incident_type === 'auto' ? null : submission.incident_type,
        media_urls: [
          ...(submission.image_urls || []),
          ...(submission.audio_urls || []),
          ...(submission.video_urls || []),
        ],
        status: 'processing',
      },
    });

    // PARALLEL STAGE 1: Extract AND Generate Embedding simultaneously
    const [extracted, embedding] = await Promise.all([
      this.gemini.extractAndClassify(
        submission.text,
        submission.image_urls
      ),
      this.gemini.generateEmbedding(submission.text),
    ]);

    // SEQUENTIAL STAGE 2: Summary (depends on extraction)
    const summary = await this.gemini.generateSummary(extracted, submission.text);

    // PARALLEL STAGE 3: Routing validation + Similar search
    const routing = this.applyRoutingRules(extracted);

    const [aiValidation, similarIncidents] = await Promise.all([
      this.gemini.validateRouting(summary.summary, routing.route, routing.rules_triggered),
      this.qdrant.searchSimilar(embedding, 3),
    ]);

    // STAGE 4: Review (agentic)
    const agenticReview = await this.gemini.agenticReview(
      summary.summary,
      routing.route,
      extracted
    );

    // Update incident
    await prisma.incident.update({
      where: { id: incidentId },
      data: {
        severity_score: extracted.severity_score,
        severity_label: extracted.severity_label,
        summary: summary.summary,
        recommended_actions: summary.recommended_actions,
        urgency: summary.urgency,
        route: routing.route,
        extracted_fields: extracted as any,
        status: 'completed',
      },
    });

    // Save audit log
    await prisma.auditLog.create({
      data: {
        incident_id: incidentId,
        audit_json: {
          version: '1.0',
          incident_id: incidentId,
          processing_time_ms: Date.now() - startTime,
          parallel_optimizations: {
            stage1: 'extraction + embedding (parallel)',
            stage3: 'validation + similar search (parallel)',
            time_saved: '~5-8 seconds per incident',
          },
        } as any,
      },
    });

    // Upsert to Qdrant
    await this.qdrant.upsertIncident(incidentId, embedding, {
      text: submission.text,
      summary: summary.summary,
      severity_score: extracted.severity_score,
      severity_label: extracted.severity_label,
      incident_type: extracted.incident_type,
      timestamp: new Date().toISOString(),
      route: routing.route,
      tags: [extracted.incident_type, extracted.severity_label.toLowerCase()],
    });

    return {
      incident_id: incidentId,
      severity_score: extracted.severity_score,
      severity_label: extracted.severity_label,
      route: routing.route,
      processing_time_ms: Date.now() - startTime,
    };
  }

  /**
   * Apply routing rules (same as IncidentService)
   */
  private applyRoutingRules(extracted: any): {
    route: string;
    rules_triggered: string[];
  } {
    let route = 'LogOnly';
    const rules_triggered: string[] = [];

    if (extracted.severity_score > 80) {
      route = 'Escalate';
      rules_triggered.push('severity>80');
    }

    if (
      extracted.risk_indicators.includes('weapon') ||
      extracted.risk_indicators.includes('injury')
    ) {
      route = 'Immediate';
      rules_triggered.push('weapon_or_injury');
    }

    if (extracted.severity_score > 50 && extracted.severity_score <= 80) {
      route = 'Review';
      rules_triggered.push('medium_high_severity');
    }

    if (extracted.emotion === 'distressed' && extracted.incident_type === 'harassment') {
      route = 'Escalate';
      rules_triggered.push('distressed_harassment');
    }

    if (extracted.severity_score <= 50 && route === 'LogOnly') {
      rules_triggered.push('low_severity');
    }

    return { route, rules_triggered };
  }

  /**
   * Get batch status and results
   */
  async getBatchStatus(batchId: string): Promise<any> {
    const batch = await prisma.$queryRaw`
      SELECT * FROM batches WHERE id = ${batchId}
    `;

    if (!batch || (batch as any[]).length === 0) {
      throw new Error('Batch not found');
    }

    return (batch as any[])[0];
  }

  /**
   * List all batches for a wallet
   */
  async listBatches(walletAddress: string, limit: number = 20): Promise<any[]> {
    const batches = await prisma.$queryRaw`
      SELECT * FROM batches
      WHERE wallet_address = ${walletAddress}
      ORDER BY created_at DESC
      LIMIT ${limit}
    `;

    return batches as any[];
  }

  /**
   * Get batch by ID with all incidents
   */
  async getBatch(batchId: string): Promise<any> {
    const batch = await prisma.batch.findUnique({
      where: { id: batchId },
      include: {
        incidents: {
          orderBy: { created_at: 'asc' },
        },
      },
    });

    return batch;
  }

  /**
   * Get batch statistics
   */
  async getBatchStatistics(batchId: string): Promise<any> {
    const batch = await prisma.batch.findUnique({
      where: { id: batchId },
      include: {
        incidents: true,
      },
    });

    if (!batch) return null;

    const incidents = batch.incidents;

    // Severity distribution
    const severityDist = incidents.reduce((acc: any, inc) => {
      const sev = inc.severity_label || 'Unknown';
      acc[sev] = (acc[sev] || 0) + 1;
      return acc;
    }, {});

    // Route distribution
    const routeDist = incidents.reduce((acc: any, inc) => {
      const route = inc.route || 'Unknown';
      acc[route] = (acc[route] || 0) + 1;
      return acc;
    }, {});

    // Type distribution
    const typeDist = incidents.reduce((acc: any, inc) => {
      const type = inc.incident_type || 'Unknown';
      acc[type] = (acc[type] || 0) + 1;
      return acc;
    }, {});

    // Average processing time per incident
    const avgProcessingTime = batch.processing_time_ms
      ? Math.round(batch.processing_time_ms / batch.total_incidents)
      : null;

    return {
      batch_id: batchId,
      total_incidents: batch.total_incidents,
      processed: batch.processed_count,
      failed: batch.failed_count,
      success_rate: ((batch.processed_count / batch.total_incidents) * 100).toFixed(2) + '%',
      processing_time_ms: batch.processing_time_ms,
      avg_processing_time_per_incident_ms: avgProcessingTime,
      performance_metrics: batch.performance_metrics,
      severity_distribution: severityDist,
      route_distribution: routeDist,
      type_distribution: typeDist,
      status: batch.status,
      created_at: batch.created_at,
      completed_at: batch.completed_at,
    };
  }

  /**
   * Retry failed incidents in a batch
   */
  async retryFailedIncidents(batchId: string): Promise<any> {
    const batch = await prisma.batch.findUnique({
      where: { id: batchId },
      include: {
        incidents: {
          where: { status: 'failed' },
        },
      },
    });

    if (!batch) return null;
    if (batch.incidents.length === 0) return null;

    console.log(`üîÑ Retrying ${batch.incidents.length} failed incidents from batch ${batchId}`);

    // Convert failed incidents back to submissions
    const submissions: IncidentSubmission[] = batch.incidents.map((inc) => ({
      text: inc.text,
      incident_type: inc.incident_type as any,
      image_urls: (inc.image_urls as string[]) || undefined,
      audio_urls: (inc.audio_urls as string[]) || undefined,
      video_urls: (inc.video_urls as string[]) || undefined,
      reporter_wallet: inc.reporter_wallet,
    }));

    // Process them as a new batch
    const retryResult = await this.processBatch(submissions, { parallel: true });

    return {
      original_batch_id: batchId,
      retry_batch_id: retryResult.batch_id,
      retried_count: submissions.length,
      result: retryResult,
    };
  }
}
